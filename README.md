![IronHack Logo](https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/upload_d5c5793015fec3be28a63c4fa3dd4d55.png)

# Recurrent Neural Networks for Electricity Price Prediction
Predicci√≥n del precio de la electricidad en el mercado el√©ctrico espa√±ol utilizando series temporales y redes neuronales recurrentes.

---

## Objetivo ‚úè

Conocer el precio de la electricidad con anterioridad puede permitir tanto a los consumidores minimizar sus gastos y a las empresas adaptar sus procesos de producci√≥n, gestionando mejor sus consumos. Por no hablar de la posibilidad de especular dentro del mercado el√©ctrico como una herramienta de trading. En todo caso un predictor del precio de la electricidad tiene una gran cantidad de aplicaciones tanto para usuarios particulares, como empresas.

---

## Introducci√≥n ‚úî

Dentro del coste total de la electricidad el coste de la energ√≠a solo representa un 35% del total. El 40% son costes regulados, es decir la parte de la factura el√©ctrica que corresponde a peajes de acceso a redes y se utilizan para pagar el mantenimiento y ampliaci√≥n de las redes. El otro 25% son impuestos; el impuesto el√©ctrico que es del 5.1127% y se aplica tanto en el t√©rmino de potencia como en el de consumo, el otro  es el IVA del 21% que se aplica sobre el impuesto el√©ctrico.

El precio de la energ√≠a se determina en el mercado diario. El mercado diario es el m√°s importante, ya que su volumen de transacciones representa el 80% del consumo el√©ctrico de Espa√±a y Portugal. Tiene lugar el d√≠a anterior al despacho de la energ√≠a y en √©l los agentes del mercado intercambian energ√≠a para cada hora del d√≠a siguiente. Es decir, hay 24 productos energ√©ticos que se comercializan, uno por cada hora del d√≠a siguiente. Los agentes del mercado env√≠an sus ofertas de compra y venta para cada una de las horas del
siguiente d√≠a. A partir de las ofertas recibidas se construyen las curvas de oferta y demanda para cada hora. El precio y el volumen de la energ√≠a intercambiado dependen del
cruce entre las curvas de oferta y demanda. Una vez se ha realizado la casaci√≥n de las curvas se identifican las ofertas casadas que se convierten en compromisos de entrega de energ√≠a y se determina el precio de la energ√≠a para esa franja horaria.

El valor y forma de estas curvas viene determinado por una serie de factores diversas. La curva de oferta depender√° en primer lugar de la climatolog√≠a por la disponibilidad de que entren las energ√≠as renovables (principalmente e√≥lica y solar), el estado de las interconexiones internacionales y el precio de los combustibles fosiles, los derechos de emission del CO2 entre otros... Por otro lado la curva de compra vendr√° determinada principalmente por la demanda de electricidad de las comercializadoras y grandes consumidores industriales.

---

## Construcci√≥n del Dataset  ‚öô

Toda esta informaci√≥n mencionada anteriormente se puede descargar de manera p√∫blica desde la plataforma de Red El√©ctrica de Espa√±a (https://www.esios.ree.es/es) y desde cualquier plataforma de inversi√≥n con los hist√≥ricos del gas y derechos de emisi√≥n del CO2 (https://www.investing.com/).

Por lo tanto las 18 variables que constituyen el dataset son, la generaci√≥n por fuente de energ√≠a, los derechos de emisi√≥n del CO2, la demanda, el precio del gas, el saldo en la conexiones internacionales y el precio spot en el mercado espa√±ol:

Hidr√°ulica, E√≥lica, Solar Fotovoltaica, Solar T√©rmica,Otras Renovables, Residuos Renovables, Nuclear, Turbinaci√≥n bombeo, Ciclo combinado, Carb√≥n, Fuel-gas, Cogeneraci√≥n, Residuos no renovables, EUA SPOT, Demanda real, TTF GAS, Saldo Interconexiones, Price

Todas est√°s variables afectan sobre el precio de la electricidad y por lo tanto tienen poder predictivo sobre ella.

El dataset abarcar√° de manera horaria desde el a√±o 2015 al 2020.

Este dataset se dividir√° en 3 partes: un dataset de entrenamiento con el 70% de los datos, un dataset de validaci√≥n con el 20% de los datos y un dataset de testeo con el  10% restante.

---

## Descripci√≥n del Proyecto üìö

Durante el analisis exploratorio de datos se han detectado algunos outliers que se han eliminado y algunas variables con poco poder predtictivo, que han sido descartadas. 

El escalado de los datos se ha realizado mediante el m√©todo MinMaxScaler() de la libreria sklearn. El entrenamiento del escalado se ha realizado √∫nicamente sobre los datos de entrenamiento pero la transformaci√≥n se ha aplicado sobre los 3 datasets: el de entrenamiento, el de validaci√≥n y el de testeo.

Al ser un analisis de series temporales para mayor simplicidad a la hora de trabajar con los distintos modelos, se ha utilizado una clase que se encarga de crear las ventanas de secuencias con el tama√±o indicado. En este caso la ventana cuenta con un input de 168 y un label de 24, con un offset de 24, es decir se introducen secuencias de 7 d√≠as para predecir el d√≠a siguiente.

Todo el proyecto se ha realizado mediante Google Colab gracias su simplicidad de maneja y la posibilidad de utilizar GPUs para el entrenamiento de los modelos.

Los modelos testeados han sido basicamente los 5 siguientes:

* Multi Step Dense
* Single Step Convolutional 
* Single Step Recurrent
* Multi Step Convolutional
* Multi Step Recurrent
* Encoder Decoder LSTM

La m√©trica utilizada para su evaluaci√≥n ha sido el Mean Absolute Error
